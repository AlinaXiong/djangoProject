下面给你一个示例的 Python 工具类 (util)，利用 kafka-python 来向 Kafka 发送数据（Producer 角色）。你可以将此示例放到一个独立文件（如 kafka_util.py）中，然后在项目的其他部分直接调用它来发送消息。示例代码如下：

python
Copy
Edit
# kafka_util.py

from kafka import KafkaProducer
import json
import logging

class KafkaProducerUtil:
    """
    一个简单的 Kafka Producer 工具类。
    使用 kafka-python 库进行消息发送。
    """

    def __init__(self,
                 bootstrap_servers,
                 client_id='my-producer',
                 retries=3,
                 acks='all',
                 max_in_flight_requests_per_connection=5,
                 key_serializer=None,
                 value_serializer=None):
        """
        初始化一个 KafkaProducer 实例。

        :param bootstrap_servers: Kafka 集群地址列表, 如 ["localhost:9092", "kafka2:9092"]
        :param client_id: 用于标识客户端的 ID
        :param retries: 发送失败时的重试次数
        :param acks: 'all' 表示等待所有副本都收到才算成功, 可选: [0, 1, 'all']
        :param max_in_flight_requests_per_connection: 并发 in-flight 请求数
        :param key_serializer: key 的序列化函数，默认为 None
        :param value_serializer: value 的序列化函数，默认为 None
        """
        self.logger = logging.getLogger(self.__class__.__name__)

        # 如果用户没传序列化函数，则默认对字典进行 json.dumps
        if value_serializer is None:
            value_serializer = lambda v: json.dumps(v).encode('utf-8')

        self.producer = KafkaProducer(
            bootstrap_servers=bootstrap_servers,
            client_id=client_id,
            retries=retries,
            acks=acks,
            max_in_flight_requests_per_connection=max_in_flight_requests_per_connection,
            key_serializer=key_serializer,
            value_serializer=value_serializer,
        )

        self.logger.info(f"KafkaProducer created with servers={bootstrap_servers}, client_id={client_id}")

    def send_message(self, topic, value, key=None, headers=None):
        """
        发送单条消息到指定 topic.

        :param topic: 目标 topic 名称
        :param value: 消息内容 (dict / str / bytes, 视value_serializer而定)
        :param key: 消息 key (可选), 一般用于分区路由
        :param headers: 可以传字典或元组列表, 例如: [("header_key", b"header_value")]
        :return: KafkaProducer 的 Future 对象，可调用 get() 等方法阻塞等待发送结果
        """
        future = None
        try:
            future = self.producer.send(topic, key=key, value=value, headers=headers)
            self.logger.debug(f"Message enqueued for topic={topic}, value={value}, key={key}")
        except Exception as e:
            self.logger.error(f"Failed to send message to Kafka: {e}", exc_info=True)
            raise e
        return future

    def flush(self, timeout=None):
        """
        强制将本地缓冲区中的消息发送到 Kafka, 并等待完成.
        :param timeout: 超时时间(秒). 若不指定, 则无限等待.
        """
        self.logger.info("Flushing Kafka producer buffer...")
        self.producer.flush(timeout=timeout)
        self.logger.info("Flush complete.")

    def close(self):
        """
        关闭 Producer, 释放资源。
        """
        self.logger.info("Closing Kafka producer.")
        self.producer.close()
使用示例
python
Copy
Edit
# main.py (或其他调用代码)
import logging
from kafka_util import KafkaProducerUtil

logging.basicConfig(level=logging.INFO)

if __name__ == "__main__":
    # 1) 初始化 Producer 工具
    producer_util = KafkaProducerUtil(
        bootstrap_servers=["localhost:9092"],
        client_id="test-producer"
    )

    # 2) 构造要发送的内容
    test_data = {
        "region": "regionA",
        "message": "Hello, Kafka!"
    }

    try:
        # 3) 发送消息
        future = producer_util.send_message(topic="test-topic", value=test_data)
        #   可选择同步等待发送结果
        record_metadata = future.get(timeout=10)
        print("Message sent, topic:", record_metadata.topic,
              "partition:", record_metadata.partition,
              "offset:", record_metadata.offset)

    except Exception as e:
        print("Error while sending message:", e)

    finally:
        # 4) 关闭前可选择 flush
        producer_util.flush()
        producer_util.close()
说明
安装依赖:
bash
Copy
Edit
pip install kafka-python
